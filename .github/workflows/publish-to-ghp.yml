name: Publish to GitHub Packages with Caching

on:
  workflow_dispatch:
    inputs:
      package_name:
        description: 'NPM package name to mirror (e.g., "axios" or "@scope/pkg")'
        required: true
      package_version:
        description: 'Package version to mirror (e.g., "latest" or a specific version)'
        required: true
        default: 'latest'

jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write # Permission to publish to GitHub Packages
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '16.13.2'
          registry-url: 'https://npm.pkg.github.com'
          scope: '@${{ github.repository_owner }}'

      - name: Sanitize Package Name
        id: sanitize_name
        run: |
          # This step removes the version from the package name if the user accidentally includes it.
          # It correctly handles both regular and scoped packages 
          SANITIZED_NAME=$(echo "${{ github.event.inputs.package_name }}" | sed 's/@[0-9][^@]*$//')
          echo "Original package name input: ${{ github.event.inputs.package_name }}, Version: ${{ github.event.inputs.package_version }}"
          echo "Sanitized package name: $SANITIZED_NAME"
          echo "sanitized_name=$SANITIZED_NAME" >> $GITHUB_OUTPUT

      - name: Resolve package version
        id: resolve_version
        run: |
          if [ "${{ github.event.inputs.package_version }}" = "latest" ]; then
            # Get the actual latest version number using the sanitized package name
            ACTUAL_VERSION=$(npm view ${{ steps.sanitize_name.outputs.sanitized_name }} version --registry=https://registry.npmjs.org/)
            echo "resolved_version=$ACTUAL_VERSION" >> $GITHUB_OUTPUT
          else
            echo "resolved_version=${{ github.event.inputs.package_version }}" >> $GITHUB_OUTPUT
          fi
          echo "Resolved version: $(echo $ACTUAL_VERSION)"

      - name: Create Safe Package Name
        id: safe_name
        run: |
          RAW_NAME="${{ steps.sanitize_name.outputs.sanitized_name }}"
          SAFE_NAME=$(echo "$RAW_NAME" | sed 's/[@\/]/-/g; s/^-*//')
          echo "Sanitized from '$RAW_NAME' â†’ '$SAFE_NAME'"
          echo "safe_name=$SAFE_NAME" >> $GITHUB_OUTPUT

      - name: Cache NPM Package and Dependencies
        id: cache_package
        uses: actions/cache@v4
        with:
          path: |
            ./cached-packages
            ./dependency-cache
          key: npm-package-with-deps-${{ steps.safe_name.outputs.safe_name }}-${{ steps.resolve_version.outputs.resolved_version }}
          restore-keys: |
            npm-package-with-deps-${{ steps.safe_name.outputs.safe_name }}-

      - name: Download Package and All Dependencies from NPM
        if: steps.cache_package.outputs.cache-hit != 'true'
        run: |
          echo "Cache miss - downloading package and all dependencies from NPM registry"
          mkdir -p cached-packages dependency-cache temp-workspace
          
          # Create a temporary package.json to install the target package and get all dependencies
          cd temp-workspace
          cat > package.json << EOF
          {
            "name": "temp-installer",
            "version": "1.0.0",
            "dependencies": {
              "${{ steps.sanitize_name.outputs.sanitized_name }}": "${{ steps.resolve_version.outputs.resolved_version }}"
            }
          }
          EOF
          
          # Install the package and all its dependencies
          echo "Installing ${{ steps.sanitize_name.outputs.sanitized_name }}@${{ steps.resolve_version.outputs.resolved_version }} and all dependencies..."
          npm install --registry=https://registry.npmjs.org/ --no-audit --no-fund
          
          # Create dependency list
          mkdir -p dependency-cache
          echo "Generating dependency list..."
          npm list --json --all > ../dependency-cache/dependency-tree.json
          
          # Extract all packages from node_modules and pack them
          echo "Packing all dependencies..."
          WORKSPACE_ROOT=$(pwd)
          cd node_modules
          
          # Use a different approach to avoid subshell issues with while loop
          find . -name "package.json" -type f > ../dependency-cache/package-list.txt
          
          while IFS= read -r pkg_json; do
            pkg_dir=$(dirname "$pkg_json")
            original_dir=$(pwd)
            cd "$pkg_dir"
            
            # Get package info
            pkg_name=$(node -p "require('./package.json').name" 2>/dev/null) || continue
            pkg_version=$(node -p "require('./package.json').version" 2>/dev/null) || continue
            
            # Skip the main package - we handle it separately
            if [ "$pkg_name" = "${{ steps.sanitize_name.outputs.sanitized_name }}" ]; then
              echo "Skipping main package: $pkg_name@$pkg_version (handled separately)"
              cd "$original_dir"
              continue
            fi
            
            echo "Processing dependency: $pkg_name@$pkg_version"
            
            # Create safe filename for caching
            safe_name=$(echo "$pkg_name" | sed 's/[@\/]/_/g')
            
            # Pack the package
            if npm pack --quiet 2>/dev/null; then
              # Move the packed file to our cache using absolute path
              tgz_file=$(ls *.tgz 2>/dev/null | head -1)
              if [ -n "$tgz_file" ]; then
                mv "$tgz_file" "${WORKSPACE_ROOT}/../dependency-cache/${safe_name}-${pkg_version}.tgz"
                echo "Cached: ${safe_name}-${pkg_version}.tgz"
              fi
            else
              echo "Failed to pack: $pkg_name@$pkg_version"
            fi
            
            cd "$original_dir"
          done < ../dependency-cache/package-list.txt
          
          # Also handle the main package separately for publishing

          # Also handle the main package separately for publishing
          cd "${WORKSPACE_ROOT}/../cached-packages"

          # Pack the main package (handle both scoped and unscoped)
          npm pack ${{ steps.sanitize_name.outputs.sanitized_name }}@${{ steps.resolve_version.outputs.resolved_version }} --registry=https://registry.npmjs.org/

          # Dynamically detect the generated tarball name (works for @scoped and normal)
          TARBALL=$(ls -1 *.tgz | head -1)
          echo "Extracting tarball: $TARBALL, for package: ${{ steps.sanitize_name.outputs.sanitized_name }}@${{ steps.resolve_version.outputs.resolved_version }} "
          
          tar -xzf "$TARBALL"
          
          cd package
          cp package.json package.json.backup
          
          # Update package.json with scoped name and publishConfig
          node -e "
            const fs = require('fs');
            const pkg = JSON.parse(fs.readFileSync('package.json', 'utf8'));
            const originalName = pkg.name;
            pkg.name = '@${{ github.repository_owner }}/' + '${{ steps.sanitize_name.outputs.sanitized_name }}';
            pkg.publishConfig = { registry: 'https://npm.pkg.github.com' };
            if (!pkg.repository) {
              pkg.repository = {
                type: 'git',
                url: 'git+https://github.com/${{ github.repository }}.git'
              };
            }
            if (pkg.scripts) {
              const scriptsToRemove = ['test', 'prepublishOnly', 'prepack', 'postpack', 'prepare'];
              scriptsToRemove.forEach(script => {
                if (pkg.scripts[script]) {
                  console.log('Removing script:', script);
                  delete pkg.scripts[script];
                }
              });
              Object.keys(pkg.scripts).forEach(scriptName => {
                if (scriptName.includes('test') || scriptName.includes('build')) {
                  console.log('Removing potentially problematic script:', scriptName);
                  delete pkg.scripts[scriptName];
                }
              });
            }
            fs.writeFileSync('package.json', JSON.stringify(pkg, null, 2));
            console.log('Updated package name from', originalName, 'to', pkg.name);
          "
          
          cd ../../
          echo "Package and all dependencies downloaded, modified, and cached"
          echo "Cached packages count: $(ls -1 dependency-cache/*.tgz 2>/dev/null | wc -l)"

      - name: Use Cached Package and Dependencies
        if: steps.cache_package.outputs.cache-hit == 'true'
        run: |
          echo "Cache hit - using cached package and dependencies"
          echo "Cached packages count: $(ls -1 dependency-cache/*.tgz 2>/dev/null | wc -l)"
          ls -la cached-packages/ dependency-cache/ | head -20

      - name: Check if package already exists in GitHub Packages
        id: check_github_package
        run: |
          # Extract the base package name (remove scope if present) for the scoped package check
          echo "Checking if npm package ${PACKAGE_NAME}@${VERSION} exists in GitHub Packages..."
          RESPONSE=$(curl -s -H "Authorization: Bearer ${NODE_AUTH_TOKEN}" \
                           -H "Accept: application/vnd.github+json" \
                           https://api.github.com/users/${GITHUB_USER}/packages/npm/${PACKAGE_NAME}/versions)
          VERSIONS=$(echo "$RESPONSE" | jq -r '.[].name' 2>/dev/null || true)
          if echo "$VERSIONS" | grep -qx "${VERSION}"; then
            echo "Package ${PACKAGE_NAME}@${VERSION} already exists in GitHub Packages."
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            if [ -n "$VERSIONS" ]; then
              echo "Package ${PACKAGE_NAME} exists, but version ${VERSION} not found. Proceeding to publish."
            else
              echo "Package ${PACKAGE_NAME} not found in GitHub Packages. Proceeding to publish."
            fi
            echo "exists=false" >> $GITHUB_OUTPUT
          fi
        env:
          NODE_AUTH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          GITHUB_USER: ${{ github.repository_owner }}
          PACKAGE_NAME: ${{ steps.sanitize_name.outputs.sanitized_name }}
          VERSION: ${{ steps.resolve_version.outputs.resolved_version }}

      - name: Publish Full Dependency Graph (ReScoped)
        if: steps.check_github_package.outputs.exists == 'false'
        run: |
          echo "Publishing full dependency graph with ReScoped names..."

          MAIN_ORIG_NAME=${{ steps.sanitize_name.outputs.sanitized_name }}
          MAIN_VERSION=${{ steps.resolve_version.outputs.resolved_version }}

          # Check if dependency-cache exists
          if [ ! -d dependency-cache ]; then
            echo "No dependency-cache directory found. Creating it..."
            mkdir -p dependency-cache
          fi

          # Check for dependency tgz files
          dep_count=$(ls dependency-cache/*.tgz 2>/dev/null | wc -l)
          if [ "$dep_count" -eq 0 ]; then
            echo "No dependency tgz files found. This package likely has no dependencies."
            echo "Only publishing the main package."
          else
            echo "Found $dep_count dependency tgz file(s)."
          fi

          echo "Main Package Tarball: cached-packages/${{ steps.safe_name.outputs.safe_name }}-${MAIN_VERSION}.tgz"
          if [ -f "cached-packages/${{ steps.safe_name.outputs.safe_name }}-${MAIN_VERSION}.tgz" ]; then
            cp "cached-packages/${{ steps.safe_name.outputs.safe_name }}-${MAIN_VERSION}.tgz" dependency-cache/
          else
            echo "ERROR: Main package tarball not found!"
            exit 1
          fi

          cd dependency-cache

          # Create publisher script with two-pass strategy: map + rewrite + publish
          cat > publish_graph.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const { execSync } = require('child_process');
          
          const owner = process.env.GH_OWNER;          
          const token = process.env.NODE_AUTH_TOKEN || '';
          const registry = 'https://npm.pkg.github.com';
          
          // Get target versions from environment if specified
          const targetMain = process.env.GH_MAIN || '';
          const targetVersion = process.env.MAIN_VERSION || '';
          
          const tgzFiles = fs.readdirSync('.').filter(f => f.endsWith('.tgz'));          
          console.log('Found tarballs:', tgzFiles.length);
          if (targetMain && targetVersion) {
            console.log(`Target: ${targetMain}@${targetVersion}`);
          }

          // Function to build a properly re-scoped name for publishing to GitHub Packages
          function getRescopedName(origName, owner) {
            if (origName.startsWith('@')) {
              const [scope, pkg] = origName.split('/');
              return `@${owner}/${scope.substring(1)}-${pkg}`;
            } else {
              return `@${owner}/${origName}`;
            }
          }
          
          // Function to check if package version exists using GitHub API
          function packageExists(packageName, version) {
              try {
                  const apiUrl = `https://api.github.com/users/${owner}/packages/npm/${packageName}/versions`;
                  const curlCmd = `curl -H "Authorization: Bearer ${token}" -H "Accept: application/vnd.github+json" "${apiUrl}"`;
                  const result = execSync(curlCmd, {
                      stdio: 'pipe',
                      timeout: 15000,
                      encoding: 'utf8'
                  });        
                  // Parse the JSON response
                  const response = JSON.parse(result);

                  if (response.message) {
                    console.log(`GitHub API Error: ${response.message}`);
                    if (response.status === '404') {
                      console.log(`Package '${packageName}' not found for user '${owner}'`);
                    }
                    return false;
                  }
                  
                  // Check if response is an array of versions
                  if (!Array.isArray(response)) {
                      console.log('Unexpected response format - not an array of versions');
                      return false;
                  }
                  // Check if the specific version exists
                  const versionExists = response.some(versionObj => {
                      return versionObj.name === version || versionObj.tag_name === version;
                  });
                  console.log(`Package ${packageName} version ${version} exists: ${versionExists}`);
                  return versionExists;
              } catch (e) {
                  console.log(`API Error: ${e.message}`);
                  return false;
              }
          }
          
          const extractRoot = '.extract';
          if (!fs.existsSync(extractRoot)) fs.mkdirSync(extractRoot);
          
          // First pass: Quick scan to identify packages and check existence
          const packagesToProcess = [];
          
          for (const file of tgzFiles) {
            const base = file.replace(/\.tgz$/, '');
            const tempDir = path.join(extractRoot, `temp_${base}`);
            
            try {
              // Quick extract just to read package.json
              if (!fs.existsSync(tempDir)) fs.mkdirSync(tempDir, { recursive: true });
              execSync(`tar -xzf ${file} -C ${tempDir} package/package.json`, { stdio: 'pipe' });
              
              const pkgPath = path.join(tempDir, 'package', 'package.json');
              if (!fs.existsSync(pkgPath)) {
                console.warn(`Missing package.json in ${file}, skipping`);
                continue;
              }
          
              const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
              const origName = pkg.name;
              const origVersion = pkg.version;
              const scopedName = getRescopedName(origName, owner);
              
              console.log(`Found: ${origName}@${origVersion}`);
              
              // If we have a target main package and version, skip other versions of that package
              if (targetMain && targetVersion && origName === targetMain && origVersion !== targetVersion) {
                console.log(`Skipping (target is ${targetMain}@${targetVersion})`);
                continue;
              }
              
              // Check if already published
              if (packageExists(origName, origVersion)) {
                console.log(`Already published as ${scopedName}@${origVersion}, skipping`);
                continue;
              }
              
              console.log(`Will process ${scopedName}@${origVersion}`);
              packagesToProcess.push({
                file,
                origName,
                origVersion,
                scopedName
              });
              
            } catch (e) {
              console.error(`Failed to scan ${file}:`, e.message);
            } finally {
              // Clean up temp directory
              try {
                if (fs.existsSync(tempDir)) {
                  execSync(`rm -rf ${tempDir}`, { stdio: 'pipe' });
                }
              } catch (e) {
                // Ignore cleanup errors
              }
            }
          }
          
          if (packagesToProcess.length === 0) {
            console.log('\nAll packages already published, nothing to do!');
            process.exit(0);
          }
          
          console.log(`\nProcessing ${packagesToProcess.length} packages`);
          
          // Second pass: Extract and build metadata only for packages that need processing
          const map = {}; // "originalName@version" -> scopedName
          const pkgMeta = {}; // "originalName@version" -> { name, version, scopedName, dir }
          
          for (const pkgInfo of packagesToProcess) {
            const { file, origName, origVersion, scopedName } = pkgInfo;
            const base = file.replace(/\.tgz$/, '');
            const outDir = path.join(extractRoot, base);
            
            try {
              if (!fs.existsSync(outDir)) fs.mkdirSync(outDir, { recursive: true });
              execSync(`tar -xzf ${file} -C ${outDir}`, { stdio: 'pipe' });
              
              const pkgPath = path.join(outDir, 'package', 'package.json');
              const key = `${origName}@${origVersion}`;
              
              map[key] = scopedName;
              pkgMeta[key] = { 
                name: origName,
                version: origVersion,
                scopedName: scopedName,
                dir: path.dirname(pkgPath) 
              };
              
              console.log(`Extracted: ${key}`);
            } catch (e) {
              console.error(`Failed to extract ${file}:`, e.message);
            }
          }
          
          if (Object.keys(pkgMeta).length === 0) {
            console.log('\nNo packages to publish after extraction');
            process.exit(0);
          }
          
          fs.writeFileSync('scoped-map.json', JSON.stringify(map, null, 2));
          
          // Helper to rewrite dependency object using map
          function rewriteDeps(obj) {
            if (!obj) return obj;
            const out = {};
          
            for (const [name, range] of Object.entries(obj)) {
              let newName = name;
          
              // First: check if this package was re-scoped earlier and exists in the map
              const mapEntry = Object.entries(map).find(([key]) => key.startsWith(name + '@'));
              if (mapEntry) {
                newName = mapEntry[1];
              } else {
                // Default fallback: apply GitHub re-scope rule
                newName = getRescopedName(name, owner);
              }
          
              out[newName] = range;
            }
          
            return out;
          }
          
          // Third pass: Rewrite & publish
          console.log('\nPublishing packages...');
          let published = 0, errors = 0;
          
          for (const [key, meta] of Object.entries(pkgMeta)) {
            const pkgJsonPath = path.join(meta.dir, 'package.json');
            const pkg = JSON.parse(fs.readFileSync(pkgJsonPath, 'utf8'));

            const newName = meta.scopedName;
            const originalVersion = meta.version;
            
            // Ensure version is not modified
            if (pkg.version !== originalVersion) {
              console.warn(`Version mismatch for ${key}: fixing ${pkg.version} -> ${originalVersion}`);
              pkg.version = originalVersion;
            }

            // FIX: Clean invalid main field (must be string, not array)
            if (Array.isArray(pkg.main)) {
              console.log(`Warning: 'main' field is an array, converting to string or removing`);
              if (pkg.main.length > 0) {
                pkg.main = pkg.main[0]; // Use first entry
              } else {
                delete pkg.main; // Remove if empty
              }
            }
            
            // Update name
            pkg.name = newName;
            pkg.publishConfig = { registry };
          
            // Rewrite dependency graphs
            pkg.dependencies = rewriteDeps(pkg.dependencies);
            pkg.devDependencies = rewriteDeps(pkg.devDependencies);
            pkg.peerDependencies = rewriteDeps(pkg.peerDependencies);
            pkg.optionalDependencies = rewriteDeps(pkg.optionalDependencies);
          
            // Clean scripts (safety)
            if (pkg.scripts) {
              for (const k of Object.keys(pkg.scripts)) {
                if (/pre|post|install|test|build/i.test(k)) delete pkg.scripts[k];
              }
            }
          
            if (!pkg.repository) {
              pkg.repository = {
                type: 'git',
                url: `git+https://github.com/${process.env.GITHUB_REPOSITORY}.git`
              };
            }
          
            fs.writeFileSync(pkgJsonPath, JSON.stringify(pkg, null, 2));
            
            // Verify version
            const verifyPkg = JSON.parse(fs.readFileSync(pkgJsonPath, 'utf8'));
            if (verifyPkg.version !== originalVersion) {
              console.error(`CRITICAL: Version changed after write for ${key}!`);
              errors++;
              continue;
            }
          
            const id = `${pkg.name}@${originalVersion}`;
            console.log(`Publishing: ${id}`);
          
            try {

              const cachePath = path.resolve(process.cwd(), '.npm-cache');
              const publishCmd = `npm publish --ignore-scripts --registry=${registry} --no-git-checks --cache="${cachePath}"`;
              
              execSync(publishCmd, {
                cwd: meta.dir,
                stdio: 'inherit',
                env: { 
                  ...process.env, 
                  NODE_AUTH_TOKEN: token
                },
                timeout: 120000
              });
              console.log(`Published: ${id}`);
              published++;
            } catch (publishError) {
              if (publishError.message && 
                  (publishError.message.includes('409') || 
                   publishError.message.includes('Cannot publish over existing version'))) {
                console.log(`Already exists (409): ${id}`);
              } else {
                console.error(`Failed: ${id}`, publishError.message);
                errors++;
              }
            }
          }
          
          console.log('\n=== Summary ===');
          console.log(`Published: ${published}`);
          console.log(`Errors: ${errors}`);
          
          if (errors > 0) {
            console.log('Some packages failed to publish');
            process.exitCode = 1;
          } else if (published === 0) {
            console.log('All packages were already published');
          } else {
            console.log(`Successfully published ${published} new package(s)`);
          }
          EOF

          GH_OWNER=${{ github.repository_owner }} GH_REPO=${{ github.repository }} \
            GH_MAIN=${{ steps.sanitize_name.outputs.sanitized_name }} \
            node publish_graph.js
        env:
          NODE_AUTH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          GH_OWNER: ${{ github.repository_owner }}

      - name: Publish Dependencies Only (if main package exists)
        if: steps.check_github_package.outputs.exists == 'true'
        run: |
          echo "Main package already exists. Publishing only dependencies that don't exist..."

          if [ ! -d dependency-cache ]; then
            echo "No dependency-cache directory found. Skipping dependencies."; exit 0; fi

          cd dependency-cache
          # Create a script to publish only dependencies (exclude main package)
          cat > publish_deps_only.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          const { execSync } = require('child_process');

          const owner = process.env.GH_OWNER;
          const mainPackage = process.env.GH_MAIN;
          const token = process.env.NODE_AUTH_TOKEN || '';

          const registry = 'https://npm.pkg.github.com';
          const tgzFiles = fs.readdirSync('.').filter(f => f.endsWith('.tgz'));
          if (!tgzFiles.length) { console.log('No tgz files found'); process.exit(0); }

          const extractRoot = '.extract';
          if (!fs.existsSync(extractRoot)) fs.mkdirSync(extractRoot);

          // Function to check if package version exists using GitHub API
          function packageExists(packageName, version) {
              try {
                  const apiUrl = `https://api.github.com/users/${owner}/packages/npm/${packageName}/versions`;
                  const curlCmd = `curl -H "Authorization: Bearer ${token}" -H "Accept: application/vnd.github+json" "${apiUrl}"`;
                  const result = execSync(curlCmd, {
                      stdio: 'pipe',
                      timeout: 15000,
                      encoding: 'utf8'
                  });        
                  // Parse the JSON response
                  const response = JSON.parse(result);

                  if (response.message) {
                    console.log(`GitHub API Error: ${response.message}`);
                    if (response.status === '404') {
                      console.log(`Package '${packageName}' not found for user '${owner}'`);
                    }
                    return false;
                  }
                  
                  // Check if response is an array of versions
                  if (!Array.isArray(response)) {
                      console.log('Unexpected response format - not an array of versions');
                      return false;
                  }
                  // Check if the specific version exists
                  const versionExists = response.some(versionObj => {
                      return versionObj.name === version || versionObj.tag_name === version;
                  });
                  console.log(`Package ${packageName} version ${version} exists: ${versionExists}`);
                  return versionExists;
              } catch (e) {
                  console.log(`API Error: ${e.message}`);
                  return false;
              }
          }

          let published = 0, skipped = 0, errors = 0;

          for (const file of tgzFiles) {
            const base = file.replace(/\.tgz$/, '');
            const outDir = path.join(extractRoot, base);
            if (!fs.existsSync(outDir)) fs.mkdirSync(outDir, { recursive: true });
            
            try {
              execSync(`tar -xzf ${file} -C ${outDir}`);
              const pkgPath = path.join(outDir, 'package', 'package.json');
              if (!fs.existsSync(pkgPath)) { console.warn('Missing package.json in', file); continue; }
              
              const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
              const originalName = pkg.name;
              
              // Skip the main package
              if (originalName === mainPackage) {
                console.log('Skipping main package:', originalName);
                continue;
              }
              
              // Transform to scoped package
              const scopedName = `@${owner}/` + originalName.split('/').pop();
              pkg.name = scopedName;
              pkg.publishConfig = { registry };
              
              // Clean potentially problematic scripts
              if (pkg.scripts) {
                for (const k of Object.keys(pkg.scripts)) {
                  if (/pre|post|install|test|build/i.test(k)) delete pkg.scripts[k];
                }
              }
              
              if (!pkg.repository) {
                pkg.repository = { type: 'git', url: `git+https://github.com/${process.env.GITHUB_REPOSITORY}.git` };
              }
              
              const packageDir = path.dirname(pkgPath);
              fs.writeFileSync(pkgPath, JSON.stringify(pkg, null, 2));
              
              const id = `${pkg.name}@${pkg.version}`;
              if (packageExists(originalName, pkg.version)) {
                console.log('Dependency already exists, skipping:', id);
                skipped++;
                continue;
              }
              
              // Publish the package
              try {
                const publishCmd = `npm publish --ignore-scripts --registry=${registry}`;
                execSync(publishCmd, { 
                  cwd: packageDir, 
                  stdio: 'inherit', 
                  env: { ...process.env, NODE_AUTH_TOKEN: token },
                  timeout: 120000
                });
                console.log('Successfully published dependency:', id);
                published++;
              } catch (publishError) {
                if (publishError.message && publishError.message.includes('409') && publishError.message.includes('Cannot publish over existing version')) {
                  console.log('Dependency already exists (409 conflict), skipping:', id);
                  skipped++;
                } else {
                  console.error('Failed to publish dependency', id, '- Error:', publishError.message);
                  errors++;
                }
              }
            } catch (e) {
              console.error('Failed to process', file, '- Error:', e.message);
              errors++;
            }
          }

          console.log('\nDependencies Summary:');
          console.log('Published:', published);
          console.log('Skipped:', skipped);
          console.log('Errors:', errors);
          EOF

          GH_OWNER=${{ github.repository_owner }} GH_MAIN=${{ steps.sanitize_name.outputs.sanitized_name }} \
            node publish_deps_only.js
        env:
          NODE_AUTH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          GH_OWNER: ${{ github.repository_owner }}

      - name: Log Package Skipped
        if: steps.check_github_package.outputs.exists == 'true'
        run: |
          # Use the correct scoped package name in the log message
          BASE_NAME=$(echo "${{ steps.sanitize_name.outputs.sanitized_name }}" | sed 's|.*/||')
          SCOPED_PACKAGE_NAME="@${{ github.repository_owner }}/${BASE_NAME}"
          echo "Skipping main package publish: ${SCOPED_PACKAGE_NAME}@${{ steps.resolve_version.outputs.resolved_version }} already exists in GitHub Packages."
          echo "Dependencies will still be processed and published if they don't exist."

      - name: Log Cache Status
        run: |
          if [ "${{ steps.cache_package.outputs.cache-hit }}" = "true" ]; then
            echo "Used cached package and dependencies from previous workflow run"
          else
            echo "Downloaded fresh package and all dependencies from NPM registry and cached for future runs"
          fi
          
          # Show summary of what was cached/processed
          echo "Summary of cached dependencies:"
          if [ -d "dependency-cache" ]; then
            dep_count=$(ls -1 dependency-cache/*.tgz 2>/dev/null | wc -l)
            echo "Total dependency packages cached: $dep_count"
            echo "Cached dependencies (first 10):"
            ls -1 dependency-cache/*.tgz 2>/dev/null | head -10 | sed 's/.*\//- /'
            if [ "$dep_count" -gt 10 ]; then
              echo "... and $((dep_count - 10)) more"
            fi
          else
            echo "No dependency cache directory found"
          fi
